{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tslearn\n",
    "# !pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tslearn\n",
    "import tslearn.datasets as ds\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import numpy as np\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "from Models.LAFS import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds.UCR_UEA_datasets().list_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX, trainY, testX, testY = ds.UCR_UEA_datasets().load_dataset(\n",
    "        \"MotorImagery\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(278, 3000, 64)\n",
      "(100, 3000, 64)\n",
      "2  Classes\n"
     ]
    }
   ],
   "source": [
    "print(trainX.shape)\n",
    "print(testX.shape)\n",
    "print(len(np.unique(trainY)),\" Classes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(trainX[0,...,27])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_std(trainX,dim = (0,1)):  ## normalize across subject and time, for each feature (7)\n",
    "    mean_channel = np.nanmean(trainX,axis = dim, keepdims = True)\n",
    "    std_channel = np.nanstd(trainX,axis = dim,keepdims =True)\n",
    "    return mean_channel,std_channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_channel,std_channel = get_mean_std(trainX)\n",
    "trainX = (trainX - mean_channel)/(std_channel + 1e-8)\n",
    "testX = (testX - mean_channel)/(std_channel + 1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Average Pooling to Reduce and smooth the size of the sequence \n",
    "trainX = torch.tensor(trainX)\n",
    "testX = torch.tensor(testX)\n",
    "\n",
    "trainX = F.avg_pool1d(trainX.permute(0,2,1),10,10).permute(0,2,1)\n",
    "trainX = np.array(trainX.detach())\n",
    "\n",
    "testX = F.avg_pool1d(testX.permute(0,2,1),10,10).permute(0,2,1)\n",
    "testX = np.array(testX.detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{np.str_('finger'): 0, np.str_('tongue'): 1}\n"
     ]
    }
   ],
   "source": [
    "### Label encoding \n",
    "unique_values = np.unique(trainY)\n",
    "unique_values = [i for i in unique_values if i is not np.nan]\n",
    "mapping = {value: idx for idx, value in enumerate(unique_values)}\n",
    "print(mapping)\n",
    "for v in unique_values:\n",
    "\n",
    "    trainY[trainY == v] = mapping[v]\n",
    "    testY[testY ==v] = mapping[v]\n",
    "trainY = np.long(trainY)\n",
    "testY = np.long(testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Simple CNN example\n",
    "class SimpleCNN_LAFS(nn.Module):\n",
    "    def __init__(self, input_size,sequence_length,filter_size = 32,kernel_size = 3, depth = 2, n_class = 2, lafs_heads = 4, use_lafs = True):\n",
    "        super(SimpleCNN_LAFS, self).__init__()\n",
    "        self.lafs = LAFS(input_size,sequence_length,k = sequence_length, lafs_heads = lafs_heads)\n",
    "        self.depth = depth\n",
    "        self.use_lafs = use_lafs\n",
    "        if use_lafs:\n",
    "            self.conv_list = nn.Conv1d(lafs_heads,filter_size,kernel_size = kernel_size,padding = 0,bias = True)\n",
    "        else:\n",
    "            self.conv_list = nn.Conv1d(input_size,filter_size,kernel_size = kernel_size,padding = 0,bias = True)\n",
    "\n",
    "\n",
    "        # self.conv_list.weight.data = torch.zeros(self.conv_list.weight.data.shape)\n",
    "\n",
    "        self.conv_list2 = nn.Conv1d(input_size,filter_size,kernel_size = kernel_size,padding = 0,bias = True)\n",
    "        # if use_lafs:\n",
    "        #     self.conv_list.append(nn.Conv1d(lafs_heads,filter_size,kernel_size = kernel_size,padding = 0))\n",
    "        # else:\n",
    "        #     self.conv_list.append(nn.Conv1d(input_size,filter_size,kernel_size = kernel_size,padding = 0))\n",
    "\n",
    "        # for d in range(1,depth):\n",
    "        #     self.conv_list.append(nn.Conv1d(filter_size,filter_size,kernel_size = kernel_size,padding = 0))\n",
    "\n",
    "        self.out = nn.Linear(filter_size, n_class)\n",
    "\n",
    "    def forward(self,x):\n",
    "        \n",
    "        ## Input X should be (Batch size, Time Steps,Features)\n",
    "        if self.use_lafs:\n",
    "            x, weights = self.lafs(x,training = True)\n",
    "        else:\n",
    "            weights = None\n",
    "        x = x.permute(0,2,1)\n",
    "        x = self.conv_list(x)\n",
    "        x = torch.relu(x)\n",
    "        # for d in range(1,self.depth):\n",
    "        #     x = self.conv_list[d](x)\n",
    "        #     x = torch.relu(x)\n",
    "        \n",
    "\n",
    "        # x_sum = torch.mean(x*x,dim= 1,keepdims = True)\n",
    "        # dis,ind = torch.topk(x_sum,dim = -1,k=10)\n",
    "        # ind = ind.repeat(1,x.shape[1],1)\n",
    "        # x = torch.gather(x,dim = -1,index = ind)\n",
    "        x,ind = torch.max(x,dim = -1)\n",
    "        x = self.out(x)\n",
    "        return x, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalized_cross_correlation(x, y, axis=-1):\n",
    "    assert x.shape == y.shape, \"Input tensors must have the same shape\"\n",
    "    \n",
    "    # Subtract the mean of each tensor along the specified axis\n",
    "    x_mean = torch.mean(x, dim=axis, keepdim=True)\n",
    "    y_mean = torch.mean(y, dim=axis, keepdim=True)\n",
    "\n",
    "    x_centered = x - x_mean\n",
    "    y_centered = y - y_mean\n",
    "\n",
    "    # Compute the numerator (sum of element-wise products of centered tensors)\n",
    "    numerator = torch.sum(x_centered * y_centered, dim=axis)\n",
    "\n",
    "    # Compute the denominator (sqrt of product of squared norms along the specified axis)\n",
    "    x_norm = torch.sqrt(torch.sum(x_centered ** 2, dim=axis))\n",
    "    y_norm = torch.sqrt(torch.sum(y_centered ** 2, dim=axis))\n",
    "    denominator = x_norm * y_norm\n",
    "\n",
    "    # Compute the normalized cross-correlation\n",
    "    ncc = numerator / denominator\n",
    "\n",
    "    return ncc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ne simple train function \n",
    "\n",
    "def create_data_loaders(X,Y, batch_size = 1, shuffle = False):\n",
    "    X_torch = torch.Tensor(X).float()\n",
    "    Y_torch = torch.Tensor(Y).long()\n",
    "    train = TensorDataset(X_torch,Y_torch) \n",
    "    train_data_loader = DataLoader(train, shuffle=shuffle, batch_size = batch_size) \n",
    "    return train_data_loader\n",
    "\n",
    "def train(model, train_dataloader, test_dataloader, lr = .003, num_epochs = 100,early_stopping = 20):\n",
    "    es = early_stopping\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    loss_function = nn.CrossEntropyLoss()\n",
    "    max_val_acc = 0.0\n",
    "    rate = .95\n",
    "    decay = .95\n",
    "    shape = model.conv_list.weight.shape\n",
    "    print(shape)\n",
    "    loss_shape = []\n",
    "    initial_weights1=  copy.deepcopy(model.conv_list.weight.view(shape[0],shape[1], -1).detach())\n",
    "    initial_weights1 = initial_weights1#.detach()\n",
    "    # plt.plot(initial_weights1[0,0,...].detach())\n",
    "    # plt.pause(.2)\n",
    "    # plt.plot(initial_weights1[1,0,...].detach())\n",
    "    # plt.pause(.2)\n",
    "    initial_weights1 = initial_weights1/initial_weights1.norm(dim=-1, keepdim=True)\n",
    "\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for i, (x,y) in enumerate(train_dataloader):  \n",
    "            outputs, weights = model(x)\n",
    "            loss = loss_function(outputs,y.long())\n",
    "            # print(model.conv_list.weight.grad)\n",
    "\n",
    "            weight = model.conv_list.weight.view(shape[0],shape[1], -1)#.detach()#.abs()#.abs()  # Shape: [out_channels, in_channels * kernel_size]\n",
    "            centered_weight = weight/(weight.norm(dim=-1, keepdim=True) + 1e-8)\n",
    "            centered_weight = centered_weight.mean(dim =0)\n",
    "            covariance_initial = torch.sum((initial_weights1*centered_weight),dim =-1).abs()\n",
    "            # covariance_initial = torch.clamp(covariance_initial,rate,1) - rate\n",
    "            alpha_new = covariance_initial.mean(dim = 1)\n",
    "            # alpha_new = covariance_initial.mean()\n",
    "\n",
    "\n",
    "            # loss = loss + loss*alpha1\n",
    "            # covariance_initial = torch.sigmoid(covariance_initial) - .5\n",
    "            alpha1 = alpha_prior.detach() - alpha_new#covariance_initial.mean()\n",
    "            alpha_prior = alpha_new\n",
    "\n",
    "            # alpah1 = torch.sigmoid(alpha1) - .5\n",
    "            loss =  loss - (alpha1.mean())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        model.eval()\n",
    "        rate = rate*decay\n",
    "        if rate < 0:\n",
    "            rate = 0\n",
    "        initial_weights1=  model.conv_list.weight.view(shape[0]*shape[1], -1)#.abs()\n",
    "        initial_weights1 = initial_weights1/initial_weights1.norm(2,dim=1, keepdim=True)\n",
    "        initial_weights1 = initial_weights1.detach()\n",
    "        # weight = model.conv_list.weight.view(shape[0]*shape[1], -1)#.abs()#.abs()  # Shape: [out_channels, in_channels * kernel_size]\n",
    "        # centered_weight = weight/(weight.norm(dim=1, keepdim=True) + 1e-8)\n",
    "\n",
    "     \n",
    "\n",
    "        # weight = model.conv_list.weight.view(shape[0]*shape[1], -1)#.abs()#.abs()  # Shape: [out_channels, in_channels * kernel_size]\n",
    "        # centered_weight = weight/(weight.norm(dim=1, keepdim=True) + 1e-8)\n",
    "        # covariance_initial = torch.sum(initial_weights1*centered_weight,dim =1).abs()\n",
    "        # alpha1 = covariance_initial.mean(dim = 0)\n",
    "        # print(alpha1)\n",
    "\n",
    "\n",
    "        val_acc = 0\n",
    "        output_ = torch.zeros((0))\n",
    "        labels_ = torch.zeros((0))\n",
    "        for i, (x,y) in enumerate(test_dataloader):  \n",
    "            outputs, weights = model(x)\n",
    "            outputs = torch.argmax(outputs,dim = -1)\n",
    "            output_ = torch.cat([output_,outputs],axis = 0)\n",
    "            labels_ = torch.cat([labels_,y],axis = 0)\n",
    "        val_acc = len(output_[output_ == labels_])/len(output_)\n",
    "        loss_shape.append(val_acc)\n",
    "        if (val_acc > max_val_acc):\n",
    "            es = early_stopping\n",
    "            print(\"val accuracy increased from \" + str(max_val_acc) + \" to \" + str(val_acc) + \" at epoch \" + str(epoch) + \". Saving new model.\")\n",
    "            best_model = copy.deepcopy(model)\n",
    "            max_val_acc = val_acc\n",
    "        else:\n",
    "            es = es - 1\n",
    "        if es <=0:\n",
    "            # plt.plot(loss_shape)\n",
    "            # plt.pause(.2)\n",
    "            # plt.plot(weight[0,...].detach())\n",
    "            # plt.pause(.2)\n",
    "            # plt.plot(weight[1,...].detach())\n",
    "            # plt.pause(.2)\n",
    "            break\n",
    "    return best_model,max_val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = torch.rand((100,7))\n",
    "x2 = torch.rand((100,7))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define simple train function \n",
    "\n",
    "def create_data_loaders(X,Y, batch_size = 1, shuffle = False):\n",
    "    X_torch = torch.Tensor(X).float()\n",
    "    Y_torch = torch.Tensor(Y).long()\n",
    "    train = TensorDataset(X_torch,Y_torch) \n",
    "    train_data_loader = DataLoader(train, shuffle=shuffle, batch_size = batch_size) \n",
    "    return train_data_loader\n",
    "\n",
    "def train(model, train_dataloader, test_dataloader, lr = .003, num_epochs = 100,early_stopping = 20):\n",
    "    es = early_stopping\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    loss_function = nn.CrossEntropyLoss()\n",
    "    max_val_acc = 0.0\n",
    "    # decay = .9\n",
    "    shape = model.conv_list.weight.shape\n",
    "    initial_weights1=  copy.deepcopy(model.conv_list.weight.view(shape[0]*shape[1], -1).detach())\n",
    "    initial_weights1 = initial_weights1/(initial_weights1.norm(2,dim=-1, keepdim=True)+ 1e-8)\n",
    "\n",
    "    rate = 1\n",
    "\n",
    "    avg_train_loss = 1000\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss_epoch = 0\n",
    "        for i, (x,y) in enumerate(train_dataloader):  \n",
    "            outputs, weights = model(x)\n",
    "            loss = loss_function(outputs,y.long())\n",
    "            # print(model.conv_list.weight.grad)\n",
    "            weight = model.conv_list.weight.view(shape[0]*shape[1], -1)#.detach()#.abs()#.abs()  # Shape: [out_channels, in_channels * kernel_size]\n",
    "            centered_weight = weight/(weight.norm(2,dim=-1, keepdim=True) + 1e-8)\n",
    "\n",
    "            covariance_initial = torch.sum((centered_weight*initial_weights1),dim = 1).abs() \n",
    "\n",
    "            alpha1 = covariance_initial.sum(dim = 0)#/(rate.sum(dim=0) + 1e-8)#/(n*n)#(covariance_initial*mask).sum()/mask.sum()\n",
    "\n",
    "\n",
    "            loss =  loss #+ rate*(alpha1)\n",
    "            train_loss_epoch += loss.detach()\n",
    "\n",
    "            #if loss > avg_train_loss:\n",
    "            loss = loss + .1*alpha1\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            # rate = torch.mean(weight_grad.abs(),dim = -1)\n",
    "            # rate = torch.mean(rate,dim = 0)\n",
    "            # rate = 1/(torch.abs(rate) + 2e-8)\n",
    "            # if i == 1:\n",
    "            #     plt.plot(weight_grad[0,...])\n",
    "            #     plt.pause(.2)\n",
    "            # if (i == 0) and (epoch == 0):\n",
    "            #     plt.plot(weight_grad[0,...].detach())\n",
    "            #     plt.pause(.2)\n",
    "\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # weight = model.conv_list.weight.view(shape[0]*shape[1], -1)#.detach()#.abs()#.abs()  # Shape: [out_channels, in_channels * kernel_size]\n",
    "            # weight_min,ind = torch.min(weight,dim = 1,keepdims = True)\n",
    "            # centered_weight = weight/(weight.norm(2,dim=-1, keepdim=True) + 1e-8)\n",
    "            # covariance_initial = torch.sum((initial_weights1*centered_weight),dim =-1).abs()#*loss.detach()\n",
    "            # rate = covariance_initial.mean().detach()\n",
    "\n",
    "\n",
    "        train_loss_epoch = train_loss_epoch/(i+1)\n",
    "        if train_loss_epoch < avg_train_loss:\n",
    "            avg_train_loss = train_loss_epoch\n",
    "            initial_weights1=  copy.deepcopy(model.conv_list.weight.view(shape[0]*shape[1], -1).detach())\n",
    "            initial_weights1 = initial_weights1/(initial_weights1.norm(2,dim=-1, keepdim=True)+ 1e-8)\n",
    "\n",
    "        model.eval()\n",
    "\n",
    "\n",
    "        val_acc = 0\n",
    "        output_ = torch.zeros((0))\n",
    "        labels_ = torch.zeros((0))\n",
    "        for i, (x,y) in enumerate(test_dataloader):  \n",
    "            outputs, weights = model(x)\n",
    "            outputs = torch.argmax(outputs,dim = -1)\n",
    "            output_ = torch.cat([output_,outputs],axis = 0)\n",
    "            labels_ = torch.cat([labels_,y],axis = 0)\n",
    "        val_acc = len(output_[output_ == labels_])/len(output_)\n",
    "        if (val_acc > max_val_acc):\n",
    "            es = early_stopping\n",
    "            print(\"val accuracy increased from \" + str(max_val_acc) + \" to \" + str(val_acc) + \" at epoch \" + str(epoch) + \". Saving new model.\")\n",
    "            best_model = copy.deepcopy(model)\n",
    "            max_val_acc = val_acc\n",
    "        else:\n",
    "            es = es - 1\n",
    "        if es <=0:\n",
    "            # plt.plot(weight[0,...].detach())\n",
    "            # plt.pause(.2)\n",
    "            # plt.plot(weight[1,...].detach())\n",
    "            # plt.pause(.2)\n",
    "            break\n",
    "    return best_model,max_val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val accuracy increased from 0.0 to 0.48 at epoch 0. Saving new model.\n",
      "val accuracy increased from 0.48 to 0.5 at epoch 1. Saving new model.\n",
      "val accuracy increased from 0.5 to 0.53 at epoch 2. Saving new model.\n",
      "val accuracy increased from 0.53 to 0.55 at epoch 20. Saving new model.\n",
      "val accuracy increased from 0.55 to 0.56 at epoch 33. Saving new model.\n",
      "0.56\n",
      "val accuracy increased from 0.0 to 0.54 at epoch 0. Saving new model.\n",
      "val accuracy increased from 0.54 to 0.58 at epoch 1. Saving new model.\n",
      "0.58\n",
      "val accuracy increased from 0.0 to 0.59 at epoch 0. Saving new model.\n",
      "0.59\n",
      "val accuracy increased from 0.0 to 0.51 at epoch 0. Saving new model.\n",
      "val accuracy increased from 0.51 to 0.53 at epoch 5. Saving new model.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[90], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m model \u001b[38;5;241m=\u001b[39m SimpleCNN_LAFS(trainX\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m],trainX\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m],filter_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m32\u001b[39m,depth \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m,kernel_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m7\u001b[39m,n_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m,use_lafs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m      4\u001b[0m train_data_loader, test_data_loader \u001b[38;5;241m=\u001b[39m create_data_loaders(trainX,trainY,batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4\u001b[39m,shuffle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m), create_data_loaders(testX,testY,batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m model,max_val_acc \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_data_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtest_data_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(max_val_acc)\n\u001b[0;32m      7\u001b[0m accs\u001b[38;5;241m.\u001b[39mappend(max_val_acc)\n",
      "Cell \u001b[1;32mIn[89], line 47\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, train_dataloader, test_dataloader, lr, num_epochs, early_stopping)\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m#if loss > avg_train_loss:\u001b[39;00m\n\u001b[0;32m     45\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m.1\u001b[39m\u001b[38;5;241m*\u001b[39malpha1\n\u001b[1;32m---> 47\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;66;03m# rate = torch.mean(weight_grad.abs(),dim = -1)\u001b[39;00m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;66;03m# rate = torch.mean(rate,dim = 0)\u001b[39;00m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;66;03m# rate = 1/(torch.abs(rate) + 2e-8)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m#     plt.plot(weight_grad[0,...].detach())\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m#     plt.pause(.2)\u001b[39;00m\n\u001b[0;32m     59\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\_tensor.py:626\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    616\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    617\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    618\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    619\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    624\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    625\u001b[0m     )\n\u001b[1;32m--> 626\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    627\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    628\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\autograd\\__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\autograd\\graph.py:823\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    821\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    822\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 823\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    825\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    826\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    827\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "accs = []\n",
    "for i in range(0,10):\n",
    "    model = SimpleCNN_LAFS(trainX.shape[-1],trainX.shape[1],filter_size = 32,depth = 1,kernel_size=7,n_class = 2,use_lafs = False)\n",
    "    train_data_loader, test_data_loader = create_data_loaders(trainX,trainY,batch_size = 4,shuffle = True), create_data_loaders(testX,testY,batch_size = 100)\n",
    "    model,max_val_acc = train(model, train_data_loader,test_data_loader)\n",
    "    print(max_val_acc)\n",
    "    accs.append(max_val_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.587)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.583)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val accuracy increased from 0.0 to 0.5 at epoch 0. Saving new model.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m model \u001b[38;5;241m=\u001b[39m SimpleCNN_LAFS(trainX\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m],trainX\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m],filter_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m,depth \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m,kernel_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,n_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m,use_lafs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,lafs_heads \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m8\u001b[39m)\n\u001b[0;32m      4\u001b[0m train_data_loader, test_data_loader \u001b[38;5;241m=\u001b[39m create_data_loaders(trainX,trainY,batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4\u001b[39m,shuffle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m), create_data_loaders(testX,testY,batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m model,max_val_acc \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_data_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtest_data_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(max_val_acc)\n\u001b[0;32m      7\u001b[0m accs\u001b[38;5;241m.\u001b[39mappend(max_val_acc)\n",
      "Cell \u001b[1;32mIn[16], line 30\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, train_dataloader, test_dataloader, lr, num_epochs, early_stopping)\u001b[0m\n\u001b[0;32m     28\u001b[0m train_loss_epoch \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (x,y) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_dataloader):  \n\u001b[1;32m---> 30\u001b[0m     outputs, weights \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss_function(outputs,y\u001b[38;5;241m.\u001b[39mlong())\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;66;03m# print(model.conv_list.weight.grad)\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[12], line 31\u001b[0m, in \u001b[0;36mSimpleCNN_LAFS.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m,x):\n\u001b[0;32m     28\u001b[0m     \n\u001b[0;32m     29\u001b[0m     \u001b[38;5;66;03m## Input X should be (Batch size, Time Steps,Features)\u001b[39;00m\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_lafs:\n\u001b[1;32m---> 31\u001b[0m         x, weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlafs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     33\u001b[0m         weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\Ryan\\Documents\\GitHub\\LocallyAdaptiveFeatureSelction2\\Models\\LAFS.py:108\u001b[0m, in \u001b[0;36mLAFS.forward\u001b[1;34m(self, x, training)\u001b[0m\n\u001b[0;32m    104\u001b[0m weights \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mgather(weights,dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,index \u001b[38;5;241m=\u001b[39m ind)\n\u001b[0;32m    106\u001b[0m weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mff_after_time_att(weights)        \n\u001b[1;32m--> 108\u001b[0m weights  \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention_across_channels\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweights\u001b[49m\u001b[43m)\u001b[49m   \n\u001b[0;32m    110\u001b[0m weights \u001b[38;5;241m=\u001b[39m weights\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    111\u001b[0m weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mff_after_channel_att(weights)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\Ryan\\Documents\\GitHub\\LocallyAdaptiveFeatureSelction2\\Models\\LAFS.py:52\u001b[0m, in \u001b[0;36mAttention.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     50\u001b[0m out \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     51\u001b[0m out \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mreshape(batch_size,time_steps, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mq_k_dim\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads)\n\u001b[1;32m---> 52\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_linear\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     53\u001b[0m out \u001b[38;5;241m=\u001b[39m out \u001b[38;5;241m+\u001b[39m x\n\u001b[0;32m     54\u001b[0m out \u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlnorm(out)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "accs = []\n",
    "for i in range(0,10):\n",
    "    model = SimpleCNN_LAFS(trainX.shape[-1],trainX.shape[1],filter_size = 1,depth = 1,kernel_size=3,n_class = 2,use_lafs = True,lafs_heads = 8)\n",
    "    train_data_loader, test_data_loader = create_data_loaders(trainX,trainY,batch_size = 4,shuffle = True), create_data_loaders(testX,testY,batch_size = 100)\n",
    "    model,max_val_acc = train(model, train_data_loader,test_data_loader)\n",
    "    print(max_val_acc)\n",
    "    accs.append(max_val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "pred, weights = model(torch.tensor(testX).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 64)"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = weights.squeeze(1).detach()\n",
    "weights = np.array(weights)\n",
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = ['EEG Channel ' + str(i) for i in np.arange(0,weights.shape[1]).tolist()]\n",
    "feature_names = np.array(feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Global Weights (Only show top 10)\n",
    "topk = 10\n",
    "importances = np.mean(weights,axis = 0)\n",
    "indices = importances.argsort()[::-1]\n",
    "indices = indices[:topk]\n",
    "plt.figure()\n",
    "plt.title(\"Global TS Feature Importances\")\n",
    "plt.bar(range(len(indices)), importances[indices], align=\"center\")\n",
    "plt.xticks(range(len(indices)), feature_names[indices], rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAnYAAAHWCAYAAAD6oMSKAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/TGe4hAAAACXBIWXMAAA9hAAAPYQGoP6dpAABQ2UlEQVR4nO3de1yUdfr/8fcMCIgIeASP4KnUNPGQpmmYUuhaSVvqWhtKZkc2i7LNDrqrbVqZYWlrfXe1rc21tNbMzHJRO0lZoJ3MNFNxNfC0gmKiwuf3hz+mJsAYNIb7w+v5eMyj5r4/c891zTUzXtyHz7iMMUYAAABwPLe/AwAAAMDZQWMHAABgCRo7AAAAS9DYAQAAWILGDgAAwBI0dgAAAJagsQMAALAEjR0AAIAlaOwAAAAsQWOHWs3lculPf/qTv8MArHHkyBHdeOONio6Olsvl0p133unvkGqctWvXyuVyae3atf4OBRaiscOv7vnnn5fL5dKnn37q71B8NnDgQLlcrl+8lTaHx48f1+zZs9W9e3eFh4crMjJS5513nm666SZt3rz5tM+1Y8eOCrd/4YUX/ir57dmzR3/605+0cePGX2X7Z6L09Zg5c6a/Q6myFStW1Lo/HB555BE9//zzuvXWW/Xiiy/q+uuv93dItcJf//pXjRgxQq1bt5bL5dLYsWMrHHvo0CHddNNNatKkierVq6dLLrlE2dnZ1RcsflWB/g4AqMkeeOAB3XjjjZ77n3zyiZ566indf//96tSpk2f5+eefL0m6+uqr9dZbb2n06NEaP368Tpw4oc2bN2v58uXq16+fOnbs+IvPOXr0aP3mN7/xWtakSZOzlJG3PXv26M9//rNiY2MVFxf3qzxHbbZixQrNnTu3VjV3q1ev1oUXXqgpU6b4O5Ra5dFHH9Xhw4fVu3dvff/99xWOKykp0bBhw/TZZ59p4sSJaty4sZ555hkNHDhQWVlZ6tChQzVGjV8DjR1wGpdeeqnX/ZCQED311FO69NJLNXDgQK91n3zyiZYvX66//OUvuv/++73WzZkzR4cOHarUc/bo0UO///3vzyRsvzt27JiCgoLkdtfOgwKFhYWqV6+ev8Pwi71796pz585nbXsnT55USUmJgoKCzto2bfTuu+969taFhYVVOG7JkiVat26dFi9erGuuuUaSNHLkSJ1zzjmaMmWKFi5cWF0h41dSO791USNt2LBBQ4cOVXh4uMLCwjR48GB99NFHZcYdOnRId911l2JjYxUcHKyWLVsqOTlZ+/fvl3TqcOjkyZPVs2dPRUREqF69ehowYIDWrFnzq8a/bds2SdJFF11UZl1AQIAaNWp0Vp5n8+bNuuaaa9SwYUOFhISoV69eWrZsmdeYgwcP6p577lHXrl0VFham8PBwDR06VJ999plnzNq1a3XBBRdIklJSUjyHfZ9//nlJUmxsbLmHcwYOHOjV1JaeL7Ro0SI9+OCDatGihUJDQ1VQUCBJ+vjjjzVkyBBFREQoNDRU8fHx+vDDD6uUe+lh/Q8++EB33HGHmjRposjISN188806fvy4Dh06pOTkZDVo0EANGjTQvffeK2OM5/E/Pbz75JNPKiYmRnXr1lV8fLy+/PLLMs+3evVqDRgwQPXq1VNkZKSGDx+ur7/+2mvMn/70J7lcLm3atEnXXnutGjRooP79+2vs2LGaO3euJHkdVi81c+ZM9evXT40aNVLdunXVs2dPLVmypEwMLpdLqampWrp0qbp06aLg4GCdd955WrlyZZmxu3fv1rhx49S8eXMFBwerTZs2uvXWW3X8+HHPmEOHDunOO+9Uq1atFBwcrPbt2+vRRx9VSUmJ17YWLVqknj17qn79+goPD1fXrl01e/bsCmtT+j7Yvn273nzzTU++O3bskHSq4Rs3bpyioqIUEhKibt266R//+IfXNn5an/T0dLVr107BwcHatGlThc+7atUq9e/fX5GRkQoLC9O5557r9YdVZb8Pfvrcc+fOVdu2bRUaGqrLLrtMu3btkjFG06ZNU8uWLVW3bl0NHz5cBw8e9NpGbGysLr/8cr3zzjuKi4tTSEiIOnfurNdee63C+H/qTD4rMTExXu+viixZskRRUVH67W9/61nWpEkTjRw5Uq+//rqKiooq9Xyoudhjhxrhq6++0oABAxQeHq57771XderU0bPPPquBAwfq3XffVZ8+fSSdOjF7wIAB+vrrr3XDDTeoR48e2r9/v5YtW6b//ve/aty4sQoKCvS3v/3Nczj08OHD+vvf/67ExEStX7/+VzvkGBMTI0l66aWXdNFFFykwsGofr6NHj3qa1FIRERGqU6eOvvrqK1100UVq0aKF7rvvPtWrV0+vvPKKkpKS9Oqrr+qqq66SJH333XdaunSpRowYoTZt2igvL0/PPvus4uPjtWnTJjVv3lydOnXS1KlTNXnyZN10000aMGCAJKlfv35VinvatGkKCgrSPffco6KiIgUFBWn16tUaOnSoevbsqSlTpsjtdmvBggUaNGiQ3n//ffXu3btKz/WHP/xB0dHR+vOf/6yPPvpIzz33nCIjI7Vu3Tq1bt1ajzzyiFasWKHHH39cXbp0UXJystfjX3jhBR0+fFi33367jh07ptmzZ2vQoEH64osvFBUVJUn6z3/+o6FDh6pt27b605/+pB9++EFPP/20LrroImVnZys2NtZrmyNGjFCHDh30yCOPyBij7t27a8+ePVq1apVefPHFMjnMnj1bV155pa677jodP35cixYt0ogRI7R8+XINGzbMa+wHH3yg1157Tbfddpvq16+vp556SldffbVycnI8fzDs2bNHvXv39pw/1bFjR+3evVtLlizR0aNHFRQUpKNHjyo+Pl67d+/WzTffrNatW2vdunWaNGmSvv/+e6Wnp0s61SyNHj1agwcP1qOPPipJ+vrrr/Xhhx9qwoQJ5dakU6dOevHFF3XXXXepZcuWuvvuuyWdahp++OEHDRw4UN9++61SU1PVpk0bLV68WGPHjtWhQ4fKbHPBggU6duyYbrrpJgUHB6thw4blPudXX32lyy+/XOeff76mTp2q4OBgffvtt17NkK/fBy+99JKOHz+uP/zhDzp48KAee+wxjRw5UoMGDdLatWv1xz/+Ud9++62efvpp3XPPPZo/f77X47du3apRo0bplltu0ZgxY7RgwQKNGDFCK1euLHME4Kd+rc/Kz23YsEE9evQosze9d+/eeu6557RlyxZ17dr1rDwX/MQAv7IFCxYYSeaTTz6pcExSUpIJCgoy27Zt8yzbs2ePqV+/vrn44os9yyZPnmwkmddee63MNkpKSowxxpw8edIUFRV5rfvf//5noqKizA033OC1XJKZMmVKpXNZvHixkWTWrFlT7vPHx8cbSSYqKsqMHj3azJ071+zcubNS296+fbuRVO6t9PkGDx5sunbtao4dO+b1vP369TMdOnTwLDt27JgpLi4us/3g4GAzdepUz7JPPvnESDILFiwoE09MTIwZM2ZMmeXx8fEmPj7ec3/NmjVGkmnbtq05evSoV1wdOnQwiYmJntoYY8zRo0dNmzZtzKWXXlqp1+Pxxx/3LCt9L/18m3379jUul8vccsstnmUnT540LVu29Iq1dJt169Y1//3vfz3LP/74YyPJ3HXXXZ5lcXFxpmnTpubAgQOeZZ999plxu90mOTnZs2zKlClGkhk9enSZHG6//XZT0dfsT18rY4w5fvy46dKlixk0aJDXckkmKCjIfPvtt15xSDJPP/20Z1lycrJxu93lfs5KX6tp06aZevXqmS1btnitv++++0xAQIDJyckxxhgzYcIEEx4ebk6ePFlu7KcTExNjhg0b5rUsPT3dSDL//Oc/vfLt27evCQsLMwUFBcaYH+sTHh5u9u7d+4vP9eSTTxpJZt++fRWOqez3QelzN2nSxBw6dMizfNKkSUaS6datmzlx4oRn+ejRo01QUJDXZzEmJsZIMq+++qpnWX5+vmnWrJnp3r27Z1npZ6b0c32mn5Wfq1evXrmf3dJ1P/8eNMaYN99800gyK1eu9Om5UPNwKBZ+V1xcrHfeeUdJSUlq27atZ3mzZs107bXX6oMPPvAc1nv11VfVrVs3z56pnyo9DBEQEOA5H6ekpEQHDx7UyZMn1atXr1/1yi+Xy6W3335bDz/8sBo0aKB//etfuv322xUTE6NRo0ZV+hy7m266SatWrfK6devWTQcPHtTq1as1cuRIHT58WPv379f+/ft14MABJSYmauvWrdq9e7ckKTg42PMXeXFxsQ4cOOA5TPVrvQZjxoxR3bp1Pfc3btyorVu36tprr9WBAwc88RYWFmrw4MF67733yhz+q6xx48Z5HXbq06ePjDEaN26cZ1lAQIB69eql7777rszjk5KS1KJFC8/93r17q0+fPlqxYoUk6fvvv9fGjRs1duxYr71F559/vi699FLPuJ+65ZZbfMrhp6/V//73P+Xn52vAgAHl1ichIUHt2rXziiM8PNyTW0lJiZYuXaorrrhCvXr1KvP40tdq8eLFGjBggBo0aOCpx/79+5WQkKDi4mK99957kqTIyEgVFhZq1apVPuVUkRUrVig6OlqjR4/2LKtTp47uuOMOHTlyRO+++67X+KuvvrpSFwxFRkZKkl5//fUK30u+fh+MGDFCERERnvulRwt+//vfe+2F79Onj44fP+75zJVq3ry51/dTeHi4kpOTtWHDBuXm5pYb46/5Wfm5H374QcHBwWWWh4SEeNbD2TgUC7/bt2+fjh49qnPPPbfMuk6dOqmkpES7du3Seeedp23btunqq6/+xW3+4x//0BNPPKHNmzfrxIkTnuVt2rQ5q7H/XHBwsB544AE98MAD+v777/Xuu+9q9uzZeuWVV1SnTh3985///MVtdOjQQQkJCWWWr1+/XsYYPfTQQ3rooYfKfezevXvVokULlZSUaPbs2XrmmWe0fft2FRcXe8acrXP9fu7nr+3WrVslnWr4KpKfn68GDRr4/FytW7f2ul/6D3GrVq3KLP/f//5X5vHlXfl3zjnn6JVXXpEk7dy5U5IqfE++/fbbZS6Q8PW9tXz5cj388MPauHGj13lN5Z0n9fN8JalBgwae3Pbt26eCggJ16dLltM+5detWff755xU2TXv37pUk3XbbbXrllVc0dOhQtWjRQpdddplGjhypIUOGVDq/n9q5c6c6dOhQ5vBf6ZXlpa93qcq+lqNGjdLf/vY33Xjjjbrvvvs0ePBg/fa3v9U111zj9Vy+fB/48t6SVOb91b59+zI1POeccySdOo8vOjq6zHP+mp+Vn6tbt26559EdO3bMsx7ORmMH6/zzn//U2LFjlZSUpIkTJ6pp06YKCAjQ9OnTPRc4VIdmzZrpd7/7na6++mqdd955euWVV/T8889X+dy70r/Y77nnHiUmJpY7pn379pJOzSX20EMP6YYbbtC0adPUsGFDud1u3XnnnZX+y7+iE7GLi4sVEBBQZvnP/0EofZ7HH3+8wvMaT3f13umU9/wVLTc/uXji1+TLP4jvv/++rrzySl188cV65pln1KxZM9WpU0cLFiwo96rEivL1NbeSkhJdeumluvfee8tdX9qANG3aVBs3btTbb7+tt956S2+99ZYWLFig5OTkMhc8/Boq+1rWrVtX7733ntasWaM333xTK1eu1Msvv6xBgwbpnXfeUUBAgM/fB768t6Sz8/76NT8rP9esWbNyp0MpXda8efOz8jzwHxo7+F2TJk0UGhqqb775psy6zZs3y+12e/5abteuXblXL/7UkiVL1LZtW7322mtezYm/5tWqU6eOzj//fG3dulX79+8v9y/2yig9TF2nTp1y9+j91JIlS3TJJZfo73//u9fyQ4cOqXHjxp77p7uKrkGDBuUePt65c6fXIfOKlB46DA8P/8V4q1vpHpKf2rJli+eCiNILYSp6TzZu3LhS05lU9Pq++uqrCgkJ0dtvv+11WGzBggWVCb+MJk2aKDw8/Bc/G+3atdORI0cqVY+goCBdccUVuuKKK1RSUqLbbrtNzz77rB566CHPHxCVFRMTo88//1wlJSVee9JKJ+0ufb2rwu12a/DgwRo8eLBmzZqlRx55RA888IDWrFmjhISEav8++Pbbb2WM8XquLVu2SFKZC25KVednJS4uTu+//36ZWnz88ccKDQ31NPdwLs6xg98FBATosssu0+uvv+6ZGkGS8vLytHDhQvXv31/h4eGSTp1789lnn+nf//53me2U/uVc+pf1T/+S/vjjj5WZmfkrZnGqWcjJySmz/NChQ8rMzFSDBg3OaKLhpk2bauDAgXr22WfL/Yt73759nv8PCAgosydh8eLFZc4HKm1Oymvg2rVrp48++shrqozly5dr165dlYq3Z8+eateunWbOnKkjR46cNt7qtnTpUq/XYv369fr44481dOhQSaf2asTFxekf//iH12vz5Zdf6p133ikzgXRFKnp9AwIC5HK5vA6R79ixQ0uXLq1SPm63W0lJSXrjjTfK/YWX0vfCyJEjlZmZqbfffrvMmEOHDunkyZOSpAMHDpTZfukk3FWZDuM3v/mNcnNz9fLLL3uWnTx5Uk8//bTCwsIUHx/v8zYllZluRJJnj1dpnNX9fbBnzx6v76eCggK98MILiouLq/CPuur8rFxzzTXKy8vzmoJl//79Wrx4sa644opyz7+Ds7DHDtVm/vz55c69NWHCBD388MOe+ahuu+02BQYG6tlnn1VRUZEee+wxz9iJEydqyZIlGjFihG644Qb17NlTBw8e1LJlyzRv3jx169ZNl19+uV577TVdddVVGjZsmLZv36558+apc+fO5X5pni2fffaZrr32Wg0dOlQDBgxQw4YNtXv3bv3jH//Qnj17lJ6eXuHhnMqaO3eu+vfvr65du2r8+PFq27at8vLylJmZqf/+97+eeeouv/xyTZ06VSkpKerXr5+++OILvfTSS2X2tLVr106RkZGaN2+e6tevr3r16qlPnz5q06aNbrzxRi1ZskRDhgzRyJEjtW3bNv3zn//0Oon/dNxut/72t79p6NChOu+885SSkqIWLVpo9+7dWrNmjcLDw/XGG2+c0etRVe3bt1f//v116623qqioSOnp6WrUqJHXIcrHH39cQ4cOVd++fTVu3DjPdCcRERGV/iWJnj17SpLuuOMOJSYmKiAgQL/73e80bNgwzZo1S0OGDNG1116rvXv3au7cuWrfvr0+//zzKuX0yCOP6J133lF8fLxuuukmderUSd9//70WL16sDz74QJGRkZo4caKWLVumyy+/XGPHjlXPnj1VWFioL774QkuWLNGOHTvUuHFj3XjjjTp48KAGDRqkli1baufOnXr66acVFxfn9YsrlXXTTTfp2Wef1dixY5WVlaXY2FgtWbJEH374odLT01W/fv0q5Tx16lS99957GjZsmGJiYrR3714988wzatmypfr37y9J1f59cM4552jcuHH65JNPFBUVpfnz5ysvL++0e2PPxmfljTfe8Hz+T5w4oc8//1wPP/ywJOnKK6/0NObXXHONLrzwQqWkpGjTpk2eX54oLi7Wn//857P0KsCv/HQ1LmqR0ikqKrrt2rXLGGNMdna2SUxMNGFhYSY0NNRccsklZt26dWW2d+DAAZOammpatGhhgoKCTMuWLc2YMWPM/v37jTGnpg545JFHTExMjAkODjbdu3c3y5cvN2PGjDExMTFe29JZnO4kLy/PzJgxw8THx5tmzZqZwMBA06BBAzNo0CCzZMmSX9x2edN7lGfbtm0mOTnZREdHmzp16pgWLVqYyy+/3Os5jh07Zu6++27TrFkzU7duXXPRRReZzMzMMlOVGGPM66+/bjp37mwCAwPLTH3yxBNPmBYtWpjg4GBz0UUXmU8//bTC6U4WL15cbrwbNmwwv/3tb02jRo1McHCwiYmJMSNHjjQZGRk+vx4VTZ1TOuXIz6e9GDNmjKlXr16523ziiSdMq1atTHBwsBkwYID57LPPysTwn//8x1x00UWmbt26Jjw83FxxxRVm06ZNlXpuY05NtfGHP/zBNGnSxLhcLq+pT/7+97+bDh06mODgYNOxY0ezYMECz7Z+SpK5/fbby2y7vOlodu7caZKTk02TJk1McHCwadu2rbn99tu9pvs4fPiwmTRpkmnfvr0JCgoyjRs3Nv369TMzZ840x48fN8YYs2TJEnPZZZeZpk2bmqCgINO6dWtz8803m++//75MHOXF9fPpTow59flISUkxjRs3NkFBQaZr165lptmp7GegVEZGhhk+fLhp3ry5CQoKMs2bNzejR4/2ms6lst8HFT13Re/v8t6Lpbm//fbb5vzzz/fU9ueP/fl0J6Wq+lkx5tR7vaLv2J+/zgcPHjTjxo0zjRo1MqGhoSY+Pv6001HBWVzGVNOZxQDgZzt27FCbNm30+OOP65577vF3OLBMbGysunTpouXLl/s7FNRinGMHAABgCRo7AAAAS9DYAQAAWIJz7AAAACzBHjsAAABL0NgBAABYwooJiktKSrRnzx7Vr1//tD+RBAAA4DTGGB0+fFjNmzf3+im48ljR2O3Zs8fzW6IAAAA22rVrl1q2bHnaMVY0dqU/R7Nr1y7Pb4oCAADYoKCgQK1atarUz+9Z0diVHn4NDw+nsQMAAFaqzOlmXDwBAABgCRo7AAAAS9DYAQAAWILGDgAAwBI0dgAAAJagsQMAALAEjR0AAIAlaOwAAAAsQWMHAABgCRo7AAAAS9DYAQAAWILGDgAAwBKB/g7AaWLve9PfIVTajhnD/B0CAACoRuyxAwAAsASNHQAAgCVo7AAAACxBYwcAAGAJGjsAAABL0NgBAABYgsYOAADAEjR2AAAAlqCxAwAAsASNHQAAgCVo7AAAACxBYwcAAGAJGjsAAABL0NgBAABYgsYOAADAEjR2AAAAlqhSYzd37lzFxsYqJCREffr00fr16ysc+9VXX+nqq69WbGysXC6X0tPTT7vtGTNmyOVy6c4776xKaAAAALWWz43dyy+/rLS0NE2ZMkXZ2dnq1q2bEhMTtXfv3nLHHz16VG3bttWMGTMUHR192m1/8sknevbZZ3X++ef7GhYAAECt53NjN2vWLI0fP14pKSnq3Lmz5s2bp9DQUM2fP7/c8RdccIEef/xx/e53v1NwcHCF2z1y5Iiuu+46/d///Z8aNGjga1gAAAC1nk+N3fHjx5WVlaWEhIQfN+B2KyEhQZmZmWcUyO23365hw4Z5bRsAAACVF+jL4P3796u4uFhRUVFey6OiorR58+YqB7Fo0SJlZ2frk08+qdT4oqIiFRUVee4XFBRU+bkBAABs4ferYnft2qUJEybopZdeUkhISKUeM336dEVERHhurVq1+pWjBAAAqPl8auwaN26sgIAA5eXleS3Py8v7xQsjKpKVlaW9e/eqR48eCgwMVGBgoN5991099dRTCgwMVHFxcZnHTJo0Sfn5+Z7brl27qvTcAAAANvGpsQsKClLPnj2VkZHhWVZSUqKMjAz17du3SgEMHjxYX3zxhTZu3Oi59erVS9ddd502btyogICAMo8JDg5WeHi41w0AAKC28+kcO0lKS0vTmDFj1KtXL/Xu3Vvp6ekqLCxUSkqKJCk5OVktWrTQ9OnTJZ264GLTpk2e/9+9e7c2btyosLAwtW/fXvXr11eXLl28nqNevXpq1KhRmeUAAAComM+N3ahRo7Rv3z5NnjxZubm5iouL08qVKz0XVOTk5Mjt/nFH4J49e9S9e3fP/ZkzZ2rmzJmKj4/X2rVrzzwDAAAASJJcxhjj7yDOVEFBgSIiIpSfn/+rH5aNve/NX3X7Z9OOGcP8HQIAADhDvvQ5fr8qFgAAAGcHjR0AAIAlaOwAAAAsQWMHAABgCRo7AAAAS9DYAQAAWILGDgAAwBI0dgAAAJagsQMAALCEzz8pBvs45dc0+CUNAABOjz12AAAAlqCxAwAAsASNHQAAgCVo7AAAACxBYwcAAGAJGjsAAABL0NgBAABYgsYOAADAEjR2AAAAlqCxAwAAsASNHQAAgCVo7AAAACwR6O8AgF9D7H1v+juEStkxY5i/QwAAWIQ9dgAAAJagsQMAALAEjR0AAIAlaOwAAAAsQWMHAABgiSo1dnPnzlVsbKxCQkLUp08frV+/vsKxX331la6++mrFxsbK5XIpPT29zJjp06frggsuUP369dW0aVMlJSXpm2++qUpoAAAAtZbPjd3LL7+stLQ0TZkyRdnZ2erWrZsSExO1d+/ecscfPXpUbdu21YwZMxQdHV3umHfffVe33367PvroI61atUonTpzQZZddpsLCQl/DAwAAqLV8nsdu1qxZGj9+vFJSUiRJ8+bN05tvvqn58+frvvvuKzP+ggsu0AUXXCBJ5a6XpJUrV3rdf/7559W0aVNlZWXp4osv9jVEAACAWsmnPXbHjx9XVlaWEhISftyA262EhARlZmaetaDy8/MlSQ0bNix3fVFRkQoKCrxuAAAAtZ1Pjd3+/ftVXFysqKgor+VRUVHKzc09KwGVlJTozjvv1EUXXaQuXbqUO2b69OmKiIjw3Fq1anVWnhsAAMDJatxVsbfffru+/PJLLVq0qMIxkyZNUn5+vue2a9euaowQAACgZvLpHLvGjRsrICBAeXl5Xsvz8vIqvDDCF6mpqVq+fLnee+89tWzZssJxwcHBCg4OPuPnAwAAsIlPe+yCgoLUs2dPZWRkeJaVlJQoIyNDffv2rXIQxhilpqbq3//+t1avXq02bdpUeVsAAAC1lc9XxaalpWnMmDHq1auXevfurfT0dBUWFnqukk1OTlaLFi00ffp0SacuuNi0aZPn/3fv3q2NGzcqLCxM7du3l3Tq8OvChQv1+uuvq379+p7z9SIiIlS3bt2zkijgdLH3venvECplx4xh/g4BAGotnxu7UaNGad++fZo8ebJyc3MVFxenlStXei6oyMnJkdv9447APXv2qHv37p77M2fO1MyZMxUfH6+1a9dKkv76179KkgYOHOj1XAsWLNDYsWN9DREAAKBW8rmxk06dC5eamlruutJmrVRsbKyMMafd3i+tBwAAwC+rcVfFAgAAoGpo7AAAACxBYwcAAGAJGjsAAABL0NgBAABYgsYOAADAEjR2AAAAlqCxAwAAsASNHQAAgCVo7AAAACxBYwcAAGAJGjsAAABL0NgBAABYgsYOAADAEjR2AAAAlgj0dwAAaq/Y+970dwiVsmPGMH+HAACVQmMHAGcRzSoAf+JQLAAAgCVo7AAAACxBYwcAAGAJGjsAAABL0NgBAABYgsYOAADAEjR2AAAAlqCxAwAAsASNHQAAgCVo7AAAACxRpcZu7ty5io2NVUhIiPr06aP169dXOParr77S1VdfrdjYWLlcLqWnp5/xNgEAAFCWz43dyy+/rLS0NE2ZMkXZ2dnq1q2bEhMTtXfv3nLHHz16VG3bttWMGTMUHR19VrYJAACAsnxu7GbNmqXx48crJSVFnTt31rx58xQaGqr58+eXO/6CCy7Q448/rt/97ncKDg4+K9sEAABAWT41dsePH1dWVpYSEhJ+3IDbrYSEBGVmZlYpgF9jmwAAALVRoC+D9+/fr+LiYkVFRXktj4qK0ubNm6sUQFW2WVRUpKKiIs/9goKCKj03AACATRx5Vez06dMVERHhubVq1crfIQEAAPidT41d48aNFRAQoLy8PK/leXl5FV4Y8Wtsc9KkScrPz/fcdu3aVaXnBgAAsIlPjV1QUJB69uypjIwMz7KSkhJlZGSob9++VQqgKtsMDg5WeHi41w0AAKC28+kcO0lKS0vTmDFj1KtXL/Xu3Vvp6ekqLCxUSkqKJCk5OVktWrTQ9OnTJZ26OGLTpk2e/9+9e7c2btyosLAwtW/fvlLbBAAAwC/zubEbNWqU9u3bp8mTJys3N1dxcXFauXKl5+KHnJwcud0/7gjcs2ePunfv7rk/c+ZMzZw5U/Hx8Vq7dm2ltgkAAIBf5nNjJ0mpqalKTU0td11ps1YqNjZWxpgz2iYAAAB+WZUaOwBA7RB735v+DqHSdswYVqlxTsmpsvkAP+XI6U4AAABQFo0dAACAJWjsAAAALEFjBwAAYAkaOwAAAEvQ2AEAAFiCxg4AAMASNHYAAACWYIJiAAAcjkmXUYo9dgAAAJagsQMAALAEjR0AAIAlaOwAAAAsQWMHAABgCa6KBQAANQ5X+lYNe+wAAAAsQWMHAABgCRo7AAAAS9DYAQAAWILGDgAAwBI0dgAAAJagsQMAALAEjR0AAIAlaOwAAAAsQWMHAABgCRo7AAAAS9DYAQAAWKJKjd3cuXMVGxurkJAQ9enTR+vXrz/t+MWLF6tjx44KCQlR165dtWLFCq/1R44cUWpqqlq2bKm6deuqc+fOmjdvXlVCAwAAqLV8buxefvllpaWlacqUKcrOzla3bt2UmJiovXv3ljt+3bp1Gj16tMaNG6cNGzYoKSlJSUlJ+vLLLz1j0tLStHLlSv3zn//U119/rTvvvFOpqalatmxZ1TMDAACoZXxu7GbNmqXx48crJSXFs2ctNDRU8+fPL3f87NmzNWTIEE2cOFGdOnXStGnT1KNHD82ZM8czZt26dRozZowGDhyo2NhY3XTTTerWrdsv7gkEAADAj3xq7I4fP66srCwlJCT8uAG3WwkJCcrMzCz3MZmZmV7jJSkxMdFrfL9+/bRs2TLt3r1bxhitWbNGW7Zs0WWXXVbuNouKilRQUOB1AwAAqO18auz279+v4uJiRUVFeS2PiopSbm5uuY/Jzc39xfFPP/20OnfurJYtWyooKEhDhgzR3LlzdfHFF5e7zenTpysiIsJza9WqlS9pAAAAWKlGXBX79NNP66OPPtKyZcuUlZWlJ554Qrfffrv+85//lDt+0qRJys/P99x27dpVzREDAADUPIG+DG7cuLECAgKUl5fntTwvL0/R0dHlPiY6Ovq043/44Qfdf//9+ve//61hw4ZJks4//3xt3LhRM2fOLHMYV5KCg4MVHBzsS+gAAADW82mPXVBQkHr27KmMjAzPspKSEmVkZKhv377lPqZv375e4yVp1apVnvEnTpzQiRMn5HZ7hxIQEKCSkhJfwgMAAKjVfNpjJ52ammTMmDHq1auXevfurfT0dBUWFiolJUWSlJycrBYtWmj69OmSpAkTJig+Pl5PPPGEhg0bpkWLFunTTz/Vc889J0kKDw9XfHy8Jk6cqLp16yomJkbvvvuuXnjhBc2aNesspgoAAGA3nxu7UaNGad++fZo8ebJyc3MVFxenlStXei6QyMnJ8dr71q9fPy1cuFAPPvig7r//fnXo0EFLly5Vly5dPGMWLVqkSZMm6brrrtPBgwcVExOjv/zlL7rlllvOQooAAAC1g8+NnSSlpqYqNTW13HVr164ts2zEiBEaMWJEhduLjo7WggULqhIKAAAA/r8acVUsAAAAzhyNHQAAgCVo7AAAACxBYwcAAGAJGjsAAABL0NgBAABYgsYOAADAEjR2AAAAlqCxAwAAsASNHQAAgCVo7AAAACxBYwcAAGAJGjsAAABL0NgBAABYgsYOAADAEjR2AAAAlqCxAwAAsASNHQAAgCVo7AAAACxBYwcAAGAJGjsAAABL0NgBAABYgsYOAADAEjR2AAAAlqCxAwAAsASNHQAAgCVo7AAAACxRpcZu7ty5io2NVUhIiPr06aP169efdvzixYvVsWNHhYSEqGvXrlqxYkWZMV9//bWuvPJKRUREqF69errggguUk5NTlfAAAABqJZ8bu5dffllpaWmaMmWKsrOz1a1bNyUmJmrv3r3ljl+3bp1Gjx6tcePGacOGDUpKSlJSUpK+/PJLz5ht27apf//+6tixo9auXavPP/9cDz30kEJCQqqeGQAAQC3jc2M3a9YsjR8/XikpKercubPmzZun0NBQzZ8/v9zxs2fP1pAhQzRx4kR16tRJ06ZNU48ePTRnzhzPmAceeEC/+c1v9Nhjj6l79+5q166drrzySjVt2rTqmQEAANQyPjV2x48fV1ZWlhISEn7cgNuthIQEZWZmlvuYzMxMr/GSlJiY6BlfUlKiN998U+ecc44SExPVtGlT9enTR0uXLvUxFQAAgNrNp8Zu//79Ki4uVlRUlNfyqKgo5ebmlvuY3Nzc047fu3evjhw5ohkzZmjIkCF65513dNVVV+m3v/2t3n333XK3WVRUpIKCAq8bAABAbRfo7wBKSkokScOHD9ddd90lSYqLi9O6des0b948xcfHl3nM9OnT9ec//7la4wQAAKjpfNpj17hxYwUEBCgvL89reV5enqKjo8t9THR09GnHN27cWIGBgercubPXmE6dOlV4VeykSZOUn5/vue3atcuXNAAAAKzkU2MXFBSknj17KiMjw7OspKREGRkZ6tu3b7mP6du3r9d4SVq1apVnfFBQkC644AJ98803XmO2bNmimJiYcrcZHBys8PBwrxsAAEBt5/Oh2LS0NI0ZM0a9evVS7969lZ6ersLCQqWkpEiSkpOT1aJFC02fPl2SNGHCBMXHx+uJJ57QsGHDtGjRIn366ad67rnnPNucOHGiRo0apYsvvliXXHKJVq5cqTfeeENr1649O1kCAADUAj43dqNGjdK+ffs0efJk5ebmKi4uTitXrvRcIJGTkyO3+8cdgf369dPChQv14IMP6v7771eHDh20dOlSdenSxTPmqquu0rx58zR9+nTdcccdOvfcc/Xqq6+qf//+ZyFFAACA2qFKF0+kpqYqNTW13HXl7WUbMWKERowYcdpt3nDDDbrhhhuqEg4AAADEb8UCAABYg8YOAADAEjR2AAAAlqCxAwAAsASNHQAAgCVo7AAAACxBYwcAAGAJGjsAAABL0NgBAABYgsYOAADAEjR2AAAAlqCxAwAAsASNHQAAgCVo7AAAACxBYwcAAGAJGjsAAABL0NgBAABYgsYOAADAEjR2AAAAlqCxAwAAsASNHQAAgCVo7AAAACxBYwcAAGAJGjsAAABL0NgBAABYgsYOAADAEjR2AAAAlqCxAwAAsESVGru5c+cqNjZWISEh6tOnj9avX3/a8YsXL1bHjh0VEhKirl27asWKFRWOveWWW+RyuZSenl6V0AAAAGotnxu7l19+WWlpaZoyZYqys7PVrVs3JSYmau/eveWOX7dunUaPHq1x48Zpw4YNSkpKUlJSkr788ssyY//973/ro48+UvPmzX3PBAAAoJbzubGbNWuWxo8fr5SUFHXu3Fnz5s1TaGio5s+fX+742bNna8iQIZo4caI6deqkadOmqUePHpozZ47XuN27d+sPf/iDXnrpJdWpU6dq2QAAANRiPjV2x48fV1ZWlhISEn7cgNuthIQEZWZmlvuYzMxMr/GSlJiY6DW+pKRE119/vSZOnKjzzjvvF+MoKipSQUGB1w0AAKC286mx279/v4qLixUVFeW1PCoqSrm5ueU+Jjc39xfHP/roowoMDNQdd9xRqTimT5+uiIgIz61Vq1a+pAEAAGAlv18Vm5WVpdmzZ+v555+Xy+Wq1GMmTZqk/Px8z23Xrl2/cpQAAAA1n0+NXePGjRUQEKC8vDyv5Xl5eYqOji73MdHR0acd//7772vv3r1q3bq1AgMDFRgYqJ07d+ruu+9WbGxsudsMDg5WeHi41w0AAKC286mxCwoKUs+ePZWRkeFZVlJSooyMDPXt27fcx/Tt29drvCStWrXKM/7666/X559/ro0bN3puzZs318SJE/X222/7mg8AAECtFejrA9LS0jRmzBj16tVLvXv3Vnp6ugoLC5WSkiJJSk5OVosWLTR9+nRJ0oQJExQfH68nnnhCw4YN06JFi/Tpp5/queeekyQ1atRIjRo18nqOOnXqKDo6Wueee+6Z5gcAAFBr+NzYjRo1Svv27dPkyZOVm5uruLg4rVy50nOBRE5OjtzuH3cE9uvXTwsXLtSDDz6o+++/Xx06dNDSpUvVpUuXs5cFAAAAfG/sJCk1NVWpqanlrlu7dm2ZZSNGjNCIESMqvf0dO3ZUJSwAAIBaze9XxQIAAODsoLEDAACwBI0dAACAJWjsAAAALEFjBwAAYAkaOwAAAEvQ2AEAAFiCxg4AAMASNHYAAACWoLEDAACwBI0dAACAJWjsAAAALEFjBwAAYAkaOwAAAEvQ2AEAAFiCxg4AAMASNHYAAACWoLEDAACwBI0dAACAJWjsAAAALEFjBwAAYAkaOwAAAEvQ2AEAAFiCxg4AAMASNHYAAACWoLEDAACwBI0dAACAJWjsAAAALFGlxm7u3LmKjY1VSEiI+vTpo/Xr1592/OLFi9WxY0eFhISoa9euWrFihWfdiRMn9Mc//lFdu3ZVvXr11Lx5cyUnJ2vPnj1VCQ0AAKDW8rmxe/nll5WWlqYpU6YoOztb3bp1U2Jiovbu3Vvu+HXr1mn06NEaN26cNmzYoKSkJCUlJenLL7+UJB09elTZ2dl66KGHlJ2drddee03ffPONrrzyyjPLDAAAoJbxubGbNWuWxo8fr5SUFHXu3Fnz5s1TaGio5s+fX+742bNna8iQIZo4caI6deqkadOmqUePHpozZ44kKSIiQqtWrdLIkSN17rnn6sILL9ScOXOUlZWlnJycM8sOAACgFvGpsTt+/LiysrKUkJDw4wbcbiUkJCgzM7Pcx2RmZnqNl6TExMQKx0tSfn6+XC6XIiMjy11fVFSkgoICrxsAAEBt51Njt3//fhUXFysqKspreVRUlHJzc8t9TG5urk/jjx07pj/+8Y8aPXq0wsPDyx0zffp0RUREeG6tWrXyJQ0AAAAr1airYk+cOKGRI0fKGKO//vWvFY6bNGmS8vPzPbddu3ZVY5QAAAA1U6Avgxs3bqyAgADl5eV5Lc/Ly1N0dHS5j4mOjq7U+NKmbufOnVq9enWFe+skKTg4WMHBwb6EDgAAYD2f9tgFBQWpZ8+eysjI8CwrKSlRRkaG+vbtW+5j+vbt6zVeklatWuU1vrSp27p1q/7zn/+oUaNGvoQFAAAA+bjHTpLS0tI0ZswY9erVS71791Z6eroKCwuVkpIiSUpOTlaLFi00ffp0SdKECRMUHx+vJ554QsOGDdOiRYv06aef6rnnnpN0qqm75pprlJ2dreXLl6u4uNhz/l3Dhg0VFBR0tnIFAACwms+N3ahRo7Rv3z5NnjxZubm5iouL08qVKz0XSOTk5Mjt/nFHYL9+/bRw4UI9+OCDuv/++9WhQwctXbpUXbp0kSTt3r1by5YtkyTFxcV5PdeaNWs0cODAKqYGAABQu/jc2ElSamqqUlNTy123du3aMstGjBihESNGlDs+NjZWxpiqhAEAAICfqFFXxQIAAKDqaOwAAAAsQWMHAABgCRo7AAAAS9DYAQAAWILGDgAAwBI0dgAAAJagsQMAALAEjR0AAIAlaOwAAAAsQWMHAABgCRo7AAAAS9DYAQAAWILGDgAAwBI0dgAAAJagsQMAALAEjR0AAIAlaOwAAAAsQWMHAABgCRo7AAAAS9DYAQAAWILGDgAAwBI0dgAAAJagsQMAALAEjR0AAIAlaOwAAAAsQWMHAABgiSo1dnPnzlVsbKxCQkLUp08frV+//rTjFy9erI4dOyokJERdu3bVihUrvNYbYzR58mQ1a9ZMdevWVUJCgrZu3VqV0AAAAGotnxu7l19+WWlpaZoyZYqys7PVrVs3JSYmau/eveWOX7dunUaPHq1x48Zpw4YNSkpKUlJSkr788kvPmMcee0xPPfWU5s2bp48//lj16tVTYmKijh07VvXMAAAAahmfG7tZs2Zp/PjxSklJUefOnTVv3jyFhoZq/vz55Y6fPXu2hgwZookTJ6pTp06aNm2aevTooTlz5kg6tbcuPT1dDz74oIYPH67zzz9fL7zwgvbs2aOlS5eeUXIAAAC1iU+N3fHjx5WVlaWEhIQfN+B2KyEhQZmZmeU+JjMz02u8JCUmJnrGb9++Xbm5uV5jIiIi1KdPnwq3CQAAgLICfRm8f/9+FRcXKyoqymt5VFSUNm/eXO5jcnNzyx2fm5vrWV+6rKIxP1dUVKSioiLP/fz8fElSQUGBD9lUTUnR0V/9Oc6Wyr4eTsnJl/qSk/+Qk105OSUfyb6cavP7TrIzpzN9DmPML471qbGrKaZPn64///nPZZa3atXKD9HUXBHp/o7g7LItH4mcnIKcnMG2nGzLRyKnM3X48GFFREScdoxPjV3jxo0VEBCgvLw8r+V5eXmKjo4u9zHR0dGnHV/637y8PDVr1sxrTFxcXLnbnDRpktLS0jz3S0pKdPDgQTVq1Egul8uXlPyuoKBArVq10q5duxQeHu7vcM4KcnIGcnIG23KyLR+JnJzCyTkZY3T48GE1b978F8f61NgFBQWpZ8+eysjIUFJSkqRTTVVGRoZSU1PLfUzfvn2VkZGhO++807Ns1apV6tu3rySpTZs2io6OVkZGhqeRKygo0Mcff6xbb7213G0GBwcrODjYa1lkZKQvqdQ44eHhjnuj/RJycgZycgbbcrItH4mcnMKpOf3SnrpSPh+KTUtL05gxY9SrVy/17t1b6enpKiwsVEpKiiQpOTlZLVq00PTp0yVJEyZMUHx8vJ544gkNGzZMixYt0qeffqrnnntOkuRyuXTnnXfq4YcfVocOHdSmTRs99NBDat68uad5BAAAwC/zubEbNWqU9u3bp8mTJys3N1dxcXFauXKl5+KHnJwcud0/Xmzbr18/LVy4UA8++KDuv/9+dejQQUuXLlWXLl08Y+69914VFhbqpptu0qFDh9S/f3+tXLlSISEhZyFFAACA2qFKF0+kpqZWeOh17dq1ZZaNGDFCI0aMqHB7LpdLU6dO1dSpU6sSjqMFBwdrypQpZQ4tOxk5OQM5OYNtOdmWj0ROTmFjTuVxmcpcOwsAAIAar0q/FQsAAICah8YOAADAEjR2AAAAlqCxAwAAsIQjf1LMqX744Qf961//0gcffKDvv/9ebrdbbdu2VVJSkgYPHuzv8Krk+PHjWrp0qTIzMz2/7RsdHa1+/fpp+PDhCgoK8nOEVbN69eoydbryyivVoUMHf4d21gwaNEgLFixQTEyMv0Opks8++0xZWVkaOHCg2rZtq6+++kpz585VSUmJrrrqKiUmJvo7xLNq165dmjJliubPn+/vUKps+/bt+vbbb9WsWTOvKa+c5IcfflBWVpYaNmyozp07e607duyYXnnlFSUnJ/spuqqz7Tuvtn0/eDGoFlu3bjUxMTGmadOmplWrVsblcplhw4aZPn36mICAADNixAhz4sQJf4fpk61bt5q2bduakJAQEx8fb0aOHGlGjhxp4uPjTUhIiGnfvr3ZunWrv8P0SV5enundu7dxu90mMDDQuN1u07NnTxMdHW0CAgLMxIkT/R2iz15//fVybwEBAWbOnDme+07y6quvmoCAANOoUSMTFhZmVq1aZSIjI01CQoJJTEw0AQEB5qWXXvJ3mGfVxo0bjdvt9ncYlXbrrbeaw4cPG2OMOXr0qLn66quN2+02LpfLuN1uc8kll3jWO8U333xjYmJiPDlcfPHFZs+ePZ71ubm5jqqRMXZ+59XG74eforGrJkOHDjU333yzKSkpMcYYM2PGDDN06FBjjDFbtmwxsbGxZsqUKX6M0HcJCQlm+PDhJj8/v8y6/Px8M3z4cHPZZZf5IbKqGzVqlElKSjL5+fnm2LFjJjU11SQnJxtjjMnIyDCNGjUy6enpfo7SN6X/CLlcrgpvTvvHqEePHubhhx82xhjzr3/9y0RGRpqpU6d61s+cOdPExcX5K7wqqagBL709+eSTjqqT2+02eXl5xhhjJk2aZFq2bGlWr15tCgsLzQcffGDatWtn7rvvPj9H6ZukpCQzbNgws2/fPrN161YzbNgw06ZNG7Nz505jjDMbOxu/82z8fvAFjV01CQ0NNVu2bPHcLyoqMnXq1DH79+83xhizdOlSExsb66/wqqRu3brmiy++qHD9559/burWrVuNEZ258PBw8+WXX3ruHzlyxNSpU8fTvL744ovm3HPP9Vd4VTJkyBAzbNgwzz+ypQIDA81XX33lp6jOTL169cz27duNMcaUlJSYOnXqmM8//9yzftu2bSYsLMxP0VWNbQ24y+XyvOe6dOliFi5c6LX+9ddfN+ecc44/Qquypk2ber3PSkpKzC233GJat25ttm3b5sjGzsbvPBu/H3zBxRPVJDIyUocPH/bcP3r0qE6ePOk5B+3888/X999/76/wqiQyMlI7duyocP2OHTsUGRlZbfGcDcHBwXK5XJ77brdbxcXFOnnypKRTP5F3upxrorfeekuDBw9Wr169tHz5cn+Hc1bUr19fBw4ckCQdOnRIJ0+e9NyXpAMHDigsLMxf4VVJs2bN9Nprr6mkpKTcW3Z2tr9D9FnpZyk3N1fnn3++17pu3bpp165d/giryn744QcFBv54arrL5dJf//pXXXHFFYqPj9eWLVv8GF3V2PidZ+P3gy9o7KrJpZdeqrS0NG3evFnbt2/XLbfcori4ONWvX1/Sqd/Ybdq0qZ+j9M2NN96o5ORkPfnkk/r888+Vl5envLw8ff7553ryySc1duxY3XTTTf4O0yf9+/fX5MmTVVhYqBMnTuj+++9X27Zt1bBhQ0nSvn371KBBAz9H6bu77rpLy5Yt0x//+EfdfPPNOnr0qL9DOiMJCQm6/fbb9dJLL2nMmDG67LLLNGnSJG3evFnffPONJk6cqP79+/s7TJ/07NlTWVlZFa53uVwyDvuhoIceekhpaWlyu93as2eP17oDBw6oXr16foqsajp27KhPP/20zPI5c+Zo+PDhuvLKK/0Q1Zmx8TvPxu8Hn/h7l2FtkZeXZy688ELP4ZSYmBiTnZ3tWb948WLz1FNP+THCqpkxY4Zp1qyZJ6/SQ0nNmjUzjz76qL/D89m2bdtMu3btTGBgoKlTp46JjIw0q1at8qxfsGCB484L+qmjR4+am2++2XTo0MEEBAQ49lBsbm6uufTSS01YWJhJTEw0hw4dMqmpqZ73YYcOHcy3337r7zB98t5775m33nqrwvVHjhwxa9eurcaIzkx8fLwZOHCg5/Z///d/XuunTZtm4uPj/RNcFT3yyCOec6PLc+uttxqXy1WNEZ05G7/zbPx+8AW/FVvNtm7dqqKiInXs2NFrl77Tbd++3Wu6kzZt2vg5oqo7evSoPvjgAx0/flwXXnihGjdu7O+Qzrply5ZpzZo1mjRpkuP2FJ/Od999p6NHj1r3+bLRd999p6CgILVs2dLfodR6R48e1YcffqiioiJrv/Ok2vP9QGMHAABgCc6xqyF27dqlG264wd9hnFVOzemHH37QBx98oE2bNpVZd+zYMb3wwgt+iOrMkBP84euvv9aCBQu0efNmSdLmzZt166236oYbbtDq1av9HB3KU1hYqAULFuiBBx7QnDlzvC46cCobczot/x4JRimnTT5aGU7MycYJSMkJ/vDWW2+ZoKAg07BhQxMSEmLeeust06RJE5OQkGAGDRpkAgICTEZGhr/DrPU6depkDhw4YIwxJicnx8TExJiIiAhzwQUXmIYNG5qmTZua7777zs9R+ubnOcXGxjo+J19wKLaaLFu27LTrv/vuO919990qLi6upojOnI05XXXVVTpx4oSef/55HTp0SHfeeac2bdqktWvXqnXr1srLy1Pz5s3Jyc9szMk2/fr106BBg/Twww9r0aJFuu2223TrrbfqL3/5iyRp0qRJysrK0jvvvOPnSGs3t9ut3NxcNW3aVL///e+1fft2rVixQhERETpy5IiuuuoqNWnSRAsXLvR3qJVmY04+8XdnWVvYNvmoMXbmZOMEpOQEfwgPD/f8pGBxcbEJDAz0mgngiy++MFFRUf4KD//fTyeSbtu2rXnnnXe81n/44YemVatW/gitymzMyRf2XhZSwzRr1kzPPPOMhg8fXu76jRs3qmfPntUc1ZmxMaeKJiBNTU1VfHy8I//CI6ea75f2fv+Uk+ZKK5341u12KyQkRBEREZ519evXV35+vr9C85mtNZJ+rNOxY8fUrFkzr3UtWrTQvn37/BHWGbExp8qisasmpZOPVtQEOXHyURtzKp2AtFOnTl7L58yZI8l5X9gSOTlBUlJSpca5XC7HHF6OjY3V1q1b1a5dO0lSZmamWrdu7Vmfk5NT5h/cmszGGpUaPHiwAgMDVVBQoG+++UZdunTxrNu5c6caNWrkx+iqxsacKovGrppMnDhRhYWFFa5v37691qxZU40RnTkbc7rqqqv0r3/9S9dff32ZdXPmzFFJSYnmzZvnh8iqjpxqvpKSEn+HcNbdeuutXg3OT/9hlU791N2gQYOqO6wqs7FGkjRlyhSv+z//qa033nhDAwYMqM6QzpiNOfmCiycAoIY6duyYQkJC/B0GToMaoaZhHjsAqEGKi4s1bdo0tWjRQmFhYfruu+8knfrd1b///e9+jg4SNULNRmMHADXIX/7yFz3//PN67LHHFBQU5FnepUsX/e1vf/NjZChFjVCT0dgBQA3ywgsv6LnnntN1112ngIAAz/Ju3bp5fsEB/kWNUJPR2AFADbJ79261b9++zPKSkhKdOHHCDxHh56gRajIaOwCoQTp37qz333+/zPIlS5aoe/fufogIP0eNUJMx3Uk1sHFiS3IiJ3+xMaefmjx5ssaMGaPdu3erpKREr732mr755hu98MILWr58ub/DqxRq5Aw21snGnHzFdCfVwO2u3I5RJ01sSU7k5C825vRz77//vqZOnarPPvtMR44cUY8ePTR58mRddtll/g6tUqiRM9hYJxtz8hWNHQAAgCU4FOtHNk5sSU7OQE413/Hjx7V3794yv3jw05/lchpq5Ay21UmyM6eKcPFENbNxYktycgZycoatW7dqwIABqlu3rmJiYtSmTRu1adNGsbGxatOmjb/D8xk1cgYb62RjTpVBY1fNbJzYkpycgZycYezYsXK73Vq+fLmysrKUnZ2t7OxsbdiwQdnZ2f4Oz2fUyBlsrJONOVWKQbVq166d+c9//mOMMSYsLMxs27bNGGPM119/bSIjI/0ZWpWRkzOQkzOEhoaar7/+2t9hnDXUyBlsrJONOVUGe+yqmY0TW5KTM5CTM3Tu3Fn79+/3dxhnDTVyBhvrZGNOlUFjV81snNiSnJyBnJzh0Ucf1b333qu1a9fqwIEDKigo8Lo5DTVyBhvrZGNOlcFVsdXMloktf4qcnIGcnCEhIUGSNHjwYK/lxhhHzr1FjZzBxjrZmFOl+PtYcG303nvvmYSEBNOkSRNTt25dc9FFF5m3337b32GdEXJyBnKq+dauXXvamxNRI2ewrU7G2JnTL2GCYgAAAEtwKNZPbJzYkpycgZxqvkOHDmn9+vXl5pScnOynqM4MNXIG2+ok2ZnTafl7l2Fts2XLFtO/f3/jdru9bi6Xy7jdbn+HVyXk5Azk5AzLli0z9evXNy6Xy0RERJjIyEjPrUGDBv4Oz2fUyBlsrJONOVUGe+yq2dixYxUYGKjly5erWbNmcrlc/g7pjJGTM5CTM9x999264YYb9Mgjjyg0NNTf4ZwxauQMNtbJxpwqg3Psqlm9evWUlZWljh07+juUs4acnIGcnKFevXr64osv1LZtW3+HclZQI2ewtU625VQZzGNXzWyc2JKcnIGcnCExMVGffvqpv8M4a6iRM9hYJxtzqgz22FWz1atX68EHH9Qjjzyirl27qk6dOl7rw8PD/RRZ1ZGTM5CTM/z973/X1KlTlZKSUm5OV155pZ8iqxpq5Aw21snGnCqDxq6aud2ndpL+/Fi/cfDEluTkDOTkDKU5lceJOVEjZ7C5TjblVBlcPFHN1qxZ4+8QzjpycgZycoafT8ngdNTIGWysk405VQZ77AAAACzBHjs/sHFiS3JyBnJyhsLCQr377rvKycnR8ePHvdbdcccdfoqq6qiRM9hYJxtz+iXssatmb7zxhq677jodOXJE4eHhXsf+XS6XDh486MfoqoacnIGcnGHDhg36zW9+o6NHj6qwsFANGzbU/v37FRoaqqZNm+q7777zd4g+oUbOYGOdbMypUqp7RuTarkOHDmbChAmmsLDQ36GcNeTkDOTkDPHx8Wb8+PGmuLjYhIWFmW3btpmcnBxz8cUXm1dffdXf4fmMGjmDjXWyMafKYI9dNbN1YktyqvnIyRkiIyP18ccf69xzz1VkZKQyMzPVqVMnffzxxxozZow2b97s7xB9Qo2cwcY62ZhTZTBBcTWzcWJLcnIGcnKGOnXqeKZpaNq0qXJyciRJERER2rVrlz9DqxJq5Aw21snGnCqDiyeq2bBhwzRx4kRt2rTJmoktyckZyMkZunfvrk8++UQdOnRQfHy8Jk+erP379+vFF19Uly5d/B2ez6iRM9hYJxtzqgwOxVYzmye2LA851Rzk5AyffvqpDh8+rEsuuUR79+5VcnKy1q1bpw4dOmj+/Pnq1q2bv0P0CTVyBhvrZGNOlUFjBwAAYAnOsQMAALAE59j5gY0TW5KTM5BTzZeXl6d77rlHGRkZ2rt3r35+UMWJh4+okTPYVifJzpx+CYdiq5mNE1uSkzOQkzMMHTpUOTk5Sk1NVbNmzcr8gPnw4cP9FFnVUCNnsLFONuZUKf6aQK+2snFiS3JyBnJyhrCwMLNhwwZ/h3HWUCNnsLFONuZUGTR21SwiIsJs3rzZ8/+bNm0yxhjz0UcfmXPPPdefoVUZOTkDOTlDp06dTHZ2tr/DOGuokTPYWCcbc6oMLp6oZjZObElOzkBOzpCenq777rtPO3bs8HcoZwU1cgYb62RjTpXBxRPVzMaJLcnJGcip5mrQoIHXeVqFhYVq166dQkNDy0yq6rQfLqdGzmBLnX7Kxpwqg4snqpmNE1uSkzOQU831j3/8o9Jjx4wZ8ytGcvZRI2ewpU4/ZWNOlUFjBwAAYAnOsQOAGmDPnj265557VFBQUGZdfn6+Jk6cqLy8PD9EhlLUCE5AY1fN8vLydP3116t58+YKDAxUQECA182JyMkZyKlmmzVrlgoKChQeHl5mXUREhA4fPqxZs2b5IbIzQ42cwaY6lbIxp8rg4olqNnbsWOXk5Oihhx4qd2JLJyInZyCnmm3lypWaN29eheuTk5M1fvx4Pfroo9UY1ZmjRs5gU51K2ZhTZXCOXTWrX7++3n//fcXFxfk7lLOGnJyBnGq2evXq6euvv1br1q3LXZ+Tk6NOnTqpsLCwmiM7M9TIGWyqUykbc6oMDsVWs1atWpX5XUGnIydnIKearW7duqedF23Hjh2qW7du9QV0llAjZ7CpTqVszKkyaOyqmY0TW5KTM5BTzdanTx+9+OKLFa5/4YUX1Lt372qM6OygRs5gU51K2ZhTZXCOXTWwcWJLciInf7ExJ0m65557dOmllyoiIkITJ05UVFSUpFMngD/22GN6/vnn9c477/g5ysqhRs5gY51szMlXNHbVID093d8hnHXk5Azk5ByXXHKJ5s6dqwkTJujJJ59UeHi4XC6X8vPzVadOHT399NMaNGiQv8OsFGrkDDbWycacfMXFEwBQg+zevVuvvPKKvv32WxljdM455+iaa65Ry5Yt/R0a/j9qhBrNoFrs3r3b3H333SY/P7/MukOHDpl77rnH5Obm+iGyqiMnZyAn+AM1cgYb62RjTr7g4olqYuPEluTkDOQEf6BGzmBjnWzMySf+7ixri/POO8+8//77Fa7/8MMPTefOnasxojNHTs5ATvAHauQMNtbJxpx8wR67arJ9+/YKJ7WUpJYtWzrukmxycgZygj9QI2ewsU425uQLGrtqYuPEluTkDOQEf6BGzmBjnWzMyRc0dtXExoktyckZyMmZDh8+rIKCAs/tyJEj/g7JJ9TIGWysk405+cTfx4Jri9WrV5uAgABz9913e12Nk5uba9LS0kxAQIDJyMjwY4S+IydnICdn2LBhgxk6dKjnflhYmHG73Z5bQECAWb9+vR8j9A01cgYb62RjTr6gsatG8+bNM8HBwcbtdpvIyEjToEED43a7TXBwsHnmmWf8HV6VkJMzkFPNd8MNN5i//OUvnvthYWHmpZdeMmvXrjVr1qwx119/vfn973/vxwh9R42cwbY6GWNnTpXFBMXVzMaJLcnJGcipZuvUqZMWLlyo7t27S5Lq16+vzz77TG3btpUkffzxxxo5cqR27tzpzzB9Ro2cwaY6lbIxp8qgsQOAGiA0NFRbtmzx/KPz5JNPaty4cZ65uHJycnTOOefo2LFj/gyzVqNGcAIungCAGiAkJMRrT89dd93lNcHqrl27FBoa6o/Q8P9RIzgBjR0A1ADdu3fX0qVLK1z/2muveQ4Bwj+oEZwg0N8BAACk2267Tb/73e8UGxurW2+9VW73qb+7i4uL9cwzz+jpp5/WwoUL/Rxl7UaN4AScYwcANcQf//hHPf7446pfv77nhPzvvvtOR44cUVpamh5//HE/RwhqhJqOxs5PDh8+rJ++9G63W2FhYX6M6MyRkzOQU8320Ucf6V//+pe2bt0qSerQoYNGjx6tCy+80M+RnRlq5Aw21amUjTmdVvXNrFK72TixJTk5AznBH6iRM9hYJxtz8gUXT1STp59+Wv379/da9uKLL2r16tXKyMjQtddeq6eeespP0VUNOTkDOTnDY489ph9++MFz/8MPP1RRUZHn/uHDh3Xbbbf5I7QqoUbOYGOdbMzJJ/7uLGuLjh07muzsbM/9sLAws23bNs/9jz76yLRu3dofoVUZOTkDOTmD2+02eXl5nvv169f3yik3N9e43W5/hFYl1MgZbKyTjTn5gj121WTnzp1q0qSJ5/7UqVPVuHFjz/1mzZopLy/PH6FVGTk5Azk5g/nZ6c4/v+801MgZbKyTjTn5gsaumtg4sSU5OQM5wR+okTPYWCcbc/IFjV01sXFiS3JyBnKCP1AjZ7CxTjbm5AsmKK4mNk5sSU7OQE7O8be//c0zDcPJkyf1/PPPew4hHT582J+h+YwaOYONdbIxJ5/49xS/2uXee+81LpfLhIeHm7i4OBMXF2fCw8ON2+0299xzj7/DqxJycgZyqvliYmJMbGzsL96chBo5g211MsbOnCqLCYqrmY0TW5KTM5AT/IEaOYONdbIxp8qgsQMAALAEF09UExsntiQnZyAnZ/jNb36j/Px8z/0ZM2bo0KFDnvsHDhxQ586d/RBZ1VAjZ7CxTjbm5BP/HgmuPWyc2JKcnIGcnMG2nGzLxxhycgobc/IFe+yqibFwYktycgZycgbbcrItH4mcnMLGnHxBYwcAAGAJGjsAqAFcLpdcLleZZag5qBGcgAmKq5FtE1tK5OQU5FTzGWM0duxYBQcHS5KOHTumW265RfXq1ZMkr5O/nYIaOYNtdZLszKmymO6kmsTGxlbqL7vt27dXQzRnBzk5Azk5Q0pKSqXGLViw4FeO5OygRs5gY51szMkXNHYAAACW4Bw7AAAAS9DYVRMbJ7YkJ2cgJ/gDNXIGG+tkY04+qa4J82o7GydMJCdnICf4AzVyBhvrZGNOvmCPXTUxFk6YSE7OQE7wB2rkDDbWycacfEFjBwAAYAkau2pi48SW5OQM5AR/oEbOYGOdbMzJF0xQXE2MhRNbkpMzkBP8gRo5g411sjEnXzCPXTWxcWJLcnIGcoI/UCNnsLFONubkCxo7AAAAS3COHQAAgCVo7AAAACxBYwcAAGAJGjsAAABL0NgBAABYgsYOAADAEjR2AAAAlqCxAwAAsASNHQAAgCX+H191smvZcFWoAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Local Weights for sample K, (Only show top 10)\n",
    "sample = 10\n",
    "topk = 10\n",
    "importances = weights[sample]\n",
    "indices = importances.argsort()[::-1]\n",
    "indices = indices[:topk]\n",
    "plt.figure()\n",
    "plt.title(\"Local TS Feature Importances for sample \" + str(sample))\n",
    "plt.bar(range(len(indices)), importances[indices], align=\"center\")\n",
    "plt.xticks(range(len(indices)), feature_names[indices], rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
